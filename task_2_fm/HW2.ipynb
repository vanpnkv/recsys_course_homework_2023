{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kaEKz7yNxate",
    "outputId": "d00fb096-da76-4a72-f047-a2fa56c68203"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for xlearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "%pip install -q polars==0.18.6 xlearn==\"0.40a1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kYVb5vRKxcua"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import xlearn as xl\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import warnings\n",
    "from typing import Tuple\n",
    "\n",
    "os.environ['USER'] = 'test'\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xflhsS256D7w"
   },
   "outputs": [],
   "source": [
    "data = pl.read_csv('../data/data.csv', try_parse_dates=True).sort('date_time')\n",
    "data = data.drop('banner_id0', 'banner_id1', 'rate0', 'rate1', 'g0', 'g1', 'coeff_sum0', 'coeff_sum1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Bwx5fIZ37uCg"
   },
   "outputs": [],
   "source": [
    "data = (\n",
    "    data\n",
    "    .with_columns([\n",
    "        pl.col('date_time').apply(lambda x: x.hour).alias('hour'),\n",
    "        pl.col('date_time').apply(lambda x: x.weekday()).alias('weekday'),\n",
    "    ])\n",
    "    .with_columns([\n",
    "        pl.col('hour').apply(lambda x: np.sin(2 * np.pi * x / 24)).alias('sin_hour'),\n",
    "        pl.col('hour').apply(lambda x: np.cos(2 * np.pi * x / 24)).alias('cos_hour'),\n",
    "        pl.col('weekday').apply(lambda x: np.sin(2 * np.pi * x / 7)).alias('sin_weekday'),\n",
    "        pl.col('weekday').apply(lambda x: np.cos(2 * np.pi * x / 7)).alias('cos_weekday'),\n",
    "    ])\n",
    "    .drop('hour', 'weekday')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RfZZiCIcb5mH"
   },
   "source": [
    "В качестве валидации будем использовать отложенную выборку за один день до тестовой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NHR4DiAB6MEh",
    "outputId": "a53e9368-cfcb-48d0-8653-907f99fece75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "строчек в тренировочной выборке: 12049046\n",
      "строчек в валидационной выборке: 1643448\n",
      "строчек в тестовой выборке: 2128978\n"
     ]
    }
   ],
   "source": [
    "test_date_threshold = data['date_time'].max().replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "val_date_threshold = test_date_threshold - datetime.timedelta(days=1)\n",
    "\n",
    "train_data = data.filter(pl.col('date_time') < val_date_threshold)\n",
    "val_data = data.filter(pl.col('date_time') >= val_date_threshold).filter(pl.col('date_time') < test_date_threshold)\n",
    "test_data = data.filter(pl.col('date_time') >= test_date_threshold)\n",
    "print(f'строчек в тренировочной выборке: {len(train_data)}')\n",
    "print(f'строчек в валидационной выборке: {len(val_data)}')\n",
    "print(f'строчек в тестовой выборке: {len(test_data)}')\n",
    "\n",
    "# sanity check\n",
    "assert len(train_data) + len(val_data) + len(test_data) == len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GjpF0AZ67zSm"
   },
   "outputs": [],
   "source": [
    "target_col = 'clicks'\n",
    "drop_columns = ['date_time', 'impressions', 'clicks']\n",
    "\n",
    "def feature_engineering(data: pl.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    # ничего не делаем, так как это будет сделано в следующей ячейке\n",
    "    X, y = data.drop(drop_columns).to_pandas(), data[target_col].to_pandas()\n",
    "    return X, y\n",
    "\n",
    "train_X, train_y = feature_engineering(train_data)\n",
    "val_X, val_y = feature_engineering(val_data)\n",
    "test_X, test_y = feature_engineering(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQAPMrqkZ44u"
   },
   "source": [
    "Для матричной факторизации будем использовать xlearn, но перед этим законвертируем все категориальные признаки с помощью функции `convert_to_ffm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NcpS2SAO6eK1"
   },
   "outputs": [],
   "source": [
    "def convert_to_ffm(path, df, type, target, numerics, categories, features, encoder):\n",
    "    # source: https://github.com/wngaw/blog/blob/master/xlearn_example/src/utils.py\n",
    "\n",
    "    # Flagging categorical and numerical fields\n",
    "    print('convert_to_ffm - START')\n",
    "    for x in numerics:\n",
    "        if(x not in encoder['catdict']):\n",
    "            encoder['catdict'][x] = 0\n",
    "    for x in categories:\n",
    "        if(x not in encoder['catdict']):\n",
    "            encoder['catdict'][x] = 1\n",
    "\n",
    "    nrows = df.shape[0]\n",
    "    tmp = df.to_dicts()\n",
    "    with open(path + str(type) + \"_ffm.txt\", \"w\") as text_file:\n",
    "        # Looping over rows to convert each row to libffm format\n",
    "        for n, r in tqdm(enumerate(range(nrows)), total=nrows):\n",
    "            datastring = \"\"\n",
    "            datarow = tmp[r]\n",
    "            datastring += str(int(datarow[target]))  # Set Target Variable here\n",
    "\n",
    "            # For numerical fields, we are creating a dummy field here\n",
    "            for i, x in enumerate(encoder['catdict'].keys()):\n",
    "                if(encoder['catdict'][x] == 0):\n",
    "                    # Not adding numerical values that are nan\n",
    "                    if math.isnan(datarow[x]) is not True:\n",
    "                        datastring = datastring + \" \"+str(i)+\":\" + str(i)+\":\" + str(datarow[x])\n",
    "                else:\n",
    "\n",
    "                    # For a new field appearing in a training example\n",
    "                    if(x not in encoder['catcodes']):\n",
    "                        encoder['catcodes'][x] = {}\n",
    "                        encoder['currentcode'] += 1\n",
    "                        encoder['catcodes'][x][datarow[x]] = encoder['currentcode']  # encoding the feature\n",
    "\n",
    "                    # For already encoded fields\n",
    "                    elif(datarow[x] not in encoder['catcodes'][x]):\n",
    "                        encoder['currentcode'] += 1\n",
    "                        encoder['catcodes'][x][datarow[x]] = encoder['currentcode']  # encoding the feature\n",
    "\n",
    "                    code = encoder['catcodes'][x][datarow[x]]\n",
    "                    datastring = datastring + \" \"+str(i)+\":\" + str(int(code))+\":1\"\n",
    "\n",
    "            datastring += '\\n'\n",
    "            text_file.write(datastring)\n",
    "\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V0p-5Ke27QPN",
    "outputId": "67999bf5-0dff-4fbe-ebb2-d0573c9794a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert_to_ffm - START\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12049046/12049046 [03:23<00:00, 59327.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert_to_ffm - START\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1643448/1643448 [00:27<00:00, 59126.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert_to_ffm - START\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2128978/2128978 [00:36<00:00, 58089.67it/s]\n"
     ]
    }
   ],
   "source": [
    "numerics = ['campaign_clicks', 'sin_hour', 'cos_hour', 'sin_weekday', 'cos_weekday']\n",
    "categories = ['zone_id', 'banner_id', 'oaid_hash', 'os_id', 'country_id']\n",
    "\n",
    "encoder = {\n",
    "    \"currentcode\": len(numerics),\n",
    "    \"catdict\": {},\n",
    "    \"catcodes\": {}\n",
    "}\n",
    "\n",
    "encoder = convert_to_ffm(\n",
    "    path='./',\n",
    "    df=train_data,\n",
    "    type='train',\n",
    "    target='clicks',\n",
    "    numerics=numerics,\n",
    "    categories=categories,\n",
    "    features=numerics + categories,\n",
    "    encoder=encoder,\n",
    ")\n",
    "\n",
    "encoder = convert_to_ffm(\n",
    "    path='./',\n",
    "    df=val_data,\n",
    "    type='val',\n",
    "    target='clicks',\n",
    "    numerics=numerics,\n",
    "    categories=categories,\n",
    "    features=numerics + categories,\n",
    "    encoder=encoder,\n",
    ")\n",
    "\n",
    "encoder = convert_to_ffm(\n",
    "    path='./',\n",
    "    df=test_data,\n",
    "    type='test',\n",
    "    target='clicks',\n",
    "    numerics=numerics,\n",
    "    categories=categories,\n",
    "    features=numerics + categories,\n",
    "    encoder=encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-62psZgNg0zJ"
   },
   "source": [
    "Переберем гиперпараметр, отвечающий за размерность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fTA4aWbz7QJe",
    "outputId": "94799158-0925-4e8f-e9bf-de744440c0e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task': 'binary', 'lr': 1.0, 'lambda': 0.001, 'k': 2, 'metric': 'auc'}\n",
      "ROC AUC = 0.8058123313718395\n",
      "Log loss = 0.15070572896121728\n",
      "{'task': 'binary', 'lr': 1.0, 'lambda': 0.001, 'k': 4, 'metric': 'auc'}\n",
      "ROC AUC = 0.8063131346050376\n",
      "Log loss = 0.15159130370529916\n",
      "{'task': 'binary', 'lr': 1.0, 'lambda': 0.001, 'k': 6, 'metric': 'auc'}\n",
      "ROC AUC = 0.8064604671303455\n",
      "Log loss = 0.15074274307975366\n",
      "{'task': 'binary', 'lr': 1.0, 'lambda': 0.001, 'k': 8, 'metric': 'auc'}\n",
      "ROC AUC = 0.8061713582273058\n",
      "Log loss = 0.15051741427097662\n"
     ]
    }
   ],
   "source": [
    "for k in [2, 4, 6, 8]:\n",
    "    params = {\n",
    "        \"task\": \"binary\",\n",
    "        \"lr\": 1.0,\n",
    "        \"lambda\": 1e-3,\n",
    "        \"k\": k,\n",
    "        \"metric\": \"auc\"\n",
    "    }\n",
    "    print(params)\n",
    "    ffm_model = xl.create_ffm()\n",
    "    ffm_model.setTrain(\"train_ffm.txt\")\n",
    "    ffm_model.setValidate(\"val_ffm.txt\")\n",
    "    ffm_model.fit(params, \"./model.out\")\n",
    "\n",
    "    ffm_model.setTest(\"val_ffm.txt\")\n",
    "    ffm_model.setSigmoid()\n",
    "    ffm_model.predict(\"./model.out\", \"./output.txt\")\n",
    "\n",
    "    with open(\"./output.txt\", 'r') as f:\n",
    "        y_pred = np.array([float(prediction) for prediction in f.readlines()])\n",
    "\n",
    "    print(f'ROC AUC = {roc_auc_score(val_y, y_pred)}')\n",
    "    print(f'Log loss = {log_loss(val_y, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99ZDKVqQfERF"
   },
   "source": [
    "Разница получилась не очень большая, но k=6 дал лучшие результаты по метрике ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "QFTPgUP2fKoX"
   },
   "outputs": [],
   "source": [
    "# соединим все данные до тестовой выборки\n",
    "!cat train_ffm.txt val_ffm.txt > train_full_ffm.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fwjm62SOaQ4B",
    "outputId": "dfe7b814-696c-49f7-cabe-f46c3a0d0d16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task': 'binary', 'lr': 1.0, 'lambda': 0.001, 'k': 6, 'metric': 'auc'}\n",
      "ROC AUC = 0.7810819121427732\n",
      "Log loss = 0.13979996266528832\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"task\": \"binary\",\n",
    "    \"lr\": 1.0,\n",
    "    \"lambda\": 1e-3,\n",
    "    \"k\": 6,\n",
    "    \"metric\": \"auc\"\n",
    "}\n",
    "print(params)\n",
    "ffm_model = xl.create_ffm()\n",
    "ffm_model.setTrain(\"train_full_ffm.txt\")\n",
    "ffm_model.fit(params, \"./model.out\")\n",
    "\n",
    "ffm_model.setTest(\"test_ffm.txt\")\n",
    "ffm_model.setSigmoid()\n",
    "ffm_model.predict(\"./model.out\", \"./output.txt\")\n",
    "\n",
    "with open(\"./output.txt\", 'r') as f:\n",
    "    y_pred = np.array([float(prediction) for prediction in f.readlines()])\n",
    "\n",
    "print(f'ROC AUC = {roc_auc_score(test_y, y_pred)}')\n",
    "print(f'Log loss = {log_loss(test_y, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZgcXZaVfwQU"
   },
   "source": [
    "Итого, включая первое задание, у нас следующие результаты\n",
    "\n",
    "### Baseline\n",
    "- ROC AUC = 0.5\n",
    "- Log loss = 0.15486198009919758\n",
    "\n",
    "### Linear regression\n",
    "- ROC AUC = 0.7448397266390455\n",
    "- Log loss = 0.1415572152890492\n",
    "\n",
    "### FFM\n",
    "- ROC AUC = 0.7810819121427732\n",
    "- Log loss = 0.13979996266528832\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
