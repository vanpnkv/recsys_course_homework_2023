{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cALBNwFeZ2XF"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, log_loss, roc_curve, roc_auc_score, auc, RocCurveDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import xlearn as xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_feathers = ['zone_id', 'banner_id', 'campaign_clicks', 'os_id', 'country_id', 'oaid_hash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfXVpHjacIAj"
   },
   "source": [
    "Загрузим данные с моего гугл диска, так как скачать напрямую по ссылке не получилось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mkCVYF60aQao",
    "outputId": "73a789cf-b8f1-4084-9628-a0eed254422d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 7.15 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ssss = '''\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "\n",
    "!cp -r \"/content/gdrive/My Drive/recsys/HW1_data.csv\" \"/content/data.csv\"\n",
    "!cp -r \"/content/gdrive/My Drive/recsys/control_data_flatten.pkl\" \"/content/control_data_flatten.pkl\"\n",
    "!cp -r \"/content/gdrive/My Drive/recsys/y_test.pkl\" \"/content/y_test.pkl\"\n",
    "!cp -r \"/content/gdrive/My Drive/recsys/data_flatten.pkl\" \"/content/data_flatten.pkl\"\n",
    "!cp -r \"/content/gdrive/My Drive/recsys/control_data.pkl\" \"/content/control_data.pkl\"\n",
    "!cp -r \"/content/gdrive/My Drive/recsys/x_test.pkl\" \"/content/x_test.pkl\"\n",
    "!cp -r \"/content/gdrive/My Drive/recsys/y_train.pkl\" \"/content/y_train.pkl\"\n",
    "!cp -r \"/content/gdrive/My Drive/recsys/data_after_celar.csv\" \"/content/data_after_celar.csv\"\n",
    "!cp -r \"/content/gdrive/My Drive/recsys/x_train.pkl\" \"/content/x_train.pkl\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HNZ6xijKZ2XM",
    "outputId": "4268c793-3d86-4d0b-d14c-cde0d601bd1e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15821472, 17)\n",
      "                    date_time  zone_id  banner_id            oaid_hash  \\\n",
      "0  2021-09-27 00:01:30.000000        0          0  5664530014561852622   \n",
      "1  2021-09-26 22:54:49.000000        1          1  5186611064559013950   \n",
      "2  2021-09-26 23:57:20.000000        2          2  2215519569292448030   \n",
      "3  2021-09-27 00:04:30.000000        3          3  6262169206735077204   \n",
      "4  2021-09-27 00:06:21.000000        4          4  4778985830203613115   \n",
      "\n",
      "   campaign_clicks  os_id  country_id  banner_id0  rate0        g0  \\\n",
      "0                0      0           0        1240  0.067  0.035016   \n",
      "1                0      0           1           1  0.002  0.054298   \n",
      "2                3      0           0           2  0.014  0.014096   \n",
      "3                0      1           1           3  0.012  0.015232   \n",
      "4                0      1           0           4  0.019  0.051265   \n",
      "\n",
      "   coeff_sum0  banner_id1  rate1        g1  coeff_sum1  impressions  clicks  \n",
      "0   -7.268846           0  0.010  0.049516   -5.369901            1       1  \n",
      "1   -2.657477         269  0.004  0.031942   -4.449220            1       1  \n",
      "2   -3.824875          21  0.014  0.014906   -3.939309            1       1  \n",
      "3   -3.461357          99  0.006  0.050671   -3.418403            1       1  \n",
      "4   -4.009026    11464230  6.790  0.032005   -2.828797            1       1  \n",
      "CPU times: user 37.5 s, sys: 16.9 s, total: 54.4 s\n",
      "Wall time: 1min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = pd.read_csv('data.csv')\n",
    "print(data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5OGgh0Yb_P_"
   },
   "source": [
    "Удалим колонки, которые нам не нужны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rmqw_VPgbXnc",
    "outputId": "fb7946e4-fbd5-42ab-8f16-f032788c30f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 770 ms, sys: 460 ms, total: 1.23 s\n",
      "Wall time: 2.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data.drop(['banner_id0', 'banner_id1', 'rate0', 'rate1', 'g0', 'g1', 'coeff_sum0', 'coeff_sum1'],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmejNUAterj6"
   },
   "source": [
    "Проанализируем информацию в стобцах.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LoSngT-EZ2XO",
    "outputId": "56cd2856-d780-4ce5-d83f-0eac71660803",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_time\n",
      "size 604712\n",
      "min, max 2021-09-01 00:02:49.000000 2021-10-02 23:59:59.000000\n",
      "zone_id\n",
      "size 3444\n",
      "min, max 0 3443\n",
      "banner_id\n",
      "size 1633\n",
      "min, max 0 1632\n",
      "oaid_hash\n",
      "size 6510316\n",
      "min, max 1116910879938 9223371107563590722\n",
      "campaign_clicks\n",
      "size 822\n",
      "min, max 0 829\n",
      "os_id\n",
      "size 11\n",
      "min, max 0 10\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "country_id\n",
      "size 17\n",
      "min, max 0 16\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "impressions\n",
      "size 1\n",
      "min, max 1 1\n",
      "[1]\n",
      "clicks\n",
      "size 2\n",
      "min, max 0 1\n",
      "[1 0]\n",
      "CPU times: user 8.68 s, sys: 1.13 s, total: 9.81 s\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def analysis(data: pd.DataFrame):\n",
    "    for colomn in data.columns:\n",
    "        uniq = data[colomn].unique()\n",
    "        colomn_uniq_size = uniq.size\n",
    "\n",
    "        print(colomn)\n",
    "        print('size', colomn_uniq_size)\n",
    "        print('min, max', uniq.min(), uniq.max())\n",
    "        if colomn_uniq_size < 50:\n",
    "            print(uniq)\n",
    "\n",
    "    pass\n",
    "\n",
    "small_data = data.head()\n",
    "#analysis(small_data)\n",
    "analysis(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объеденим в каждой колонке все поля, где различных значений меньше 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.where(data.apply(lambda x: x.map(x.value_counts())) >= 10, -1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YJaJwXpcn5i"
   },
   "source": [
    "во всех полях кроме даты малое количество различных значений, поэтому будем использовать ван хот енкодинг. Так же можно удалить столбец \"impressions\" так как во всех строчках данных одно и то же значение.\n",
    "Время использовать не будем, так как данные всего за месяц, если не получиться ,то будем добавлять признаки на подоби и день недели/час дня."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P2uiUNGjcyC1",
    "outputId": "292b6d60-cfcb-4133-998d-f28416253ec8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 375 ms, sys: 140 ms, total: 515 ms\n",
      "Wall time: 512 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data.drop(['impressions'],axis = 1, inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перенумеруем все поля в колонках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[my_feathers] = data[my_feathers].apply(lambda x: pd.factorize(x)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Be3UAz3nd4-e"
   },
   "outputs": [],
   "source": [
    "data.to_csv('data_after_celar.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним для простоты, так как файл слишком большой\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vqsmg5leeEqB",
    "outputId": "397c8a2f-8059-4b6a-cd08-a920b3926f67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15821472, 8)\n",
      "                    date_time  zone_id  banner_id  oaid_hash  campaign_clicks  \\\n",
      "0  2021-09-27 00:01:30.000000        0          0          0                0   \n",
      "1  2021-09-26 22:54:49.000000        1          1          0                0   \n",
      "2  2021-09-26 23:57:20.000000        2          2          1                1   \n",
      "3  2021-09-27 00:04:30.000000        3          3          0                0   \n",
      "4  2021-09-27 00:06:21.000000        4          4          0                0   \n",
      "\n",
      "   os_id  country_id  clicks  \n",
      "0      0           0       1  \n",
      "1      0           1       1  \n",
      "2      0           0       1  \n",
      "3      1           1       1  \n",
      "4      1           0       1  \n",
      "CPU times: user 14.5 s, sys: 4.84 s, total: 19.4 s\n",
      "Wall time: 27.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data = pd.read_csv('data_after_celar.csv')#.astype(pd.SparseDtype(int, fill_value=0))\n",
    "print(data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217990\n"
     ]
    }
   ],
   "source": [
    "max_value = 0\n",
    "for colomn in my_feathers:\n",
    "    data[colomn].unique()\n",
    "    #max_value = max(max_value, data[colomn].max() + 1)\n",
    "    max_value = max(max_value, data[colomn].unique().size + 1)\n",
    "print(max_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отделим последний день от набора данных, так как по условию задания нужно сравнить метрики на последнем дне. и нет смыла на нем обучаться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask ready\n",
      "mask ready\n",
      "control ready\n",
      "mask ready\n",
      "mask ready\n",
      "data ready\n",
      "control without date ready\n",
      "data without date ready\n",
      "CPU times: user 3.21 s, sys: 496 ms, total: 3.71 s\n",
      "Wall time: 4.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mask = data['date_time'] >= '2021-10-02'\n",
    "print('mask ready')\n",
    "control_data = data[mask]\n",
    "print('mask ready')\n",
    "control_data.reset_index(drop=True, inplace = True)\n",
    "print('control ready')\n",
    "mask = data['date_time'] < '2021-10-02'\n",
    "print('mask ready')\n",
    "data = data[mask]\n",
    "print('mask ready')\n",
    "data.reset_index(drop=True, inplace = True)\n",
    "print('data ready')\n",
    "\n",
    "control_data.drop(['date_time'], axis = 1, inplace = True)\n",
    "print('control without date ready')\n",
    "data.drop(['date_time'], axis = 1, inplace = True)\n",
    "print('data without date ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "control_data.to_csv('control_data_flatten.csv', index=False)\n",
    "data.to_csv('data_flatten.csv', index=False)\n",
    "\n",
    "y_control = control_data['clicks']\n",
    "y_control.to_csv('y_control.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2119894, 7)\n",
      "(13701578, 7)\n",
      "CPU times: user 4.94 s, sys: 939 ms, total: 5.88 s\n",
      "Wall time: 6.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "control_data = pd.read_csv('control_data_flatten.csv')#.astype(pd.SparseDtype(int, fill_value=0))\n",
    "print(control_data.shape)\n",
    "data = pd.read_csv('data_flatten.csv')#.astype(pd.SparseDtype(int, fill_value=0))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отделим разделим оставшиеся даные на тест и траин."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data.sample(frac=0.2)\n",
    "train = data.drop(test.index)\n",
    "del data\n",
    "train = train.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('test.csv', index=False)\n",
    "train.to_csv('train.csv', index=False)\n",
    "\n",
    "y_test = test['clicks']\n",
    "y_test.to_csv('y_test.csv', index=False)\n",
    "\n",
    "y_train = train['clicks']\n",
    "y_train.to_csv('y_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/ycjuan/libffm\n",
    "Привидем данные к такому виду, чтобы использовать ffm в xlearn.\n",
    "\n",
    "max_value - максимальное колиичество уникальных значений в колонке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = 217990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200000\n",
      "400000\n",
      "600000\n",
      "800000\n",
      "1000000\n",
      "1200000\n",
      "1400000\n",
      "1600000\n",
      "1800000\n",
      "2000000\n",
      "2200000\n",
      "2400000\n",
      "2600000\n",
      "0\n",
      "200000\n",
      "400000\n",
      "600000\n",
      "800000\n",
      "1000000\n",
      "1200000\n",
      "1400000\n",
      "1600000\n",
      "1800000\n",
      "2000000\n",
      "2200000\n",
      "2400000\n",
      "2600000\n",
      "2800000\n",
      "3000000\n",
      "3200000\n",
      "3400000\n",
      "3600000\n",
      "3800000\n",
      "4000000\n",
      "4200000\n",
      "4400000\n",
      "4600000\n",
      "4800000\n",
      "5000000\n",
      "5200000\n",
      "5400000\n",
      "5600000\n",
      "5800000\n",
      "6000000\n",
      "6200000\n",
      "6400000\n",
      "6600000\n",
      "6800000\n",
      "7000000\n",
      "7200000\n",
      "7400000\n",
      "7600000\n",
      "7800000\n",
      "8000000\n",
      "8200000\n",
      "8400000\n",
      "8600000\n",
      "8800000\n",
      "9000000\n",
      "9200000\n",
      "9400000\n",
      "9600000\n",
      "9800000\n",
      "10000000\n",
      "10200000\n",
      "10400000\n",
      "10600000\n",
      "10800000\n",
      "0\n",
      "200000\n",
      "400000\n",
      "600000\n",
      "800000\n",
      "1000000\n",
      "1200000\n",
      "1400000\n",
      "1600000\n",
      "1800000\n",
      "2000000\n",
      "CPU times: user 22min 12s, sys: 3.14 s, total: 22min 16s\n",
      "Wall time: 22min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def feature_engineering(file_name, data):\n",
    "    with open(file_name, \"w\") as f:\n",
    "        for index, row in data.iterrows():\n",
    "            if index % 200000 == 0:\n",
    "                print(index)\n",
    "            result_row = str(row['clicks'])\n",
    "            for i, feather in enumerate(my_feathers):\n",
    "                s = ' ' + str(i) + ':' + str(i * max_value + row[feather]) + ':1'\n",
    "                result_row += s\n",
    "            result_row += '\\n'\n",
    "            f.write(result_row)\n",
    "        \n",
    "            \n",
    "feature_engineering('test.txt', test)\n",
    "feature_engineering('train.txt', train)\n",
    "feature_engineering('control_data.txt', control_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_value = [1, 2, 4, 8]\n",
    "l_value = [0.00001, 0.0001, 0.001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k :  1  lambda :  0.001\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[35m\u001b[1m[ WARNING    ] Validation file not found, xLearn has already disable early-stopping.\u001b[0m\n",
      "\u001b[35m\u001b[1m[ WARNING    ] Validation file not found, xLearn has already disable (-x auc) option.\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mxLearn uses 4 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1307939\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 6\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 8.11 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 249.47 MB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.22 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     1            0.106440                4.74\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     2            0.104980                4.88\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     3            0.104342                4.83\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m     4            0.103738                4.80\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m     5            0.103245                4.83\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m     6            0.102779                4.50\n",
      "\u001b[32m[ \u001b[0m  70%\u001b[32m      ]\u001b[0m     7            0.102336                4.50\n",
      "\u001b[32m[ \u001b[0m  80%\u001b[32m      ]\u001b[0m     8            0.101956                4.38\n",
      "\u001b[32m[ \u001b[0m  90%\u001b[32m      ]\u001b[0m     9            0.101583                4.37\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m    10            0.101260                4.92\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: ./model.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 1.31 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 56.49 (sec)\u001b[0m\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 4 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from ./model.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1307939\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 1\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 6\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 0.11 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 1.73 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.102122\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 4.25 (sec)\u001b[0m\n",
      "roc_auc :  0.7865092932507044  log_loss :  0.10211690872968326\n",
      "k :  2  lambda :  0.001\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[35m\u001b[1m[ WARNING    ] Validation file not found, xLearn has already disable early-stopping.\u001b[0m\n",
      "\u001b[35m\u001b[1m[ WARNING    ] Validation file not found, xLearn has already disable (-x auc) option.\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mxLearn uses 4 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1307939\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 6\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 22.77 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 249.47 MB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.61 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     1            0.106418                4.75\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     2            0.104928                4.74\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     3            0.104231                4.69\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m     4            0.103592                4.54\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m     5            0.103044                4.42\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m     6            0.102552                4.49\n",
      "\u001b[32m[ \u001b[0m  70%\u001b[32m      ]\u001b[0m     7            0.102144                4.54\n",
      "\u001b[32m[ \u001b[0m  80%\u001b[32m      ]\u001b[0m     8            0.101732                4.60\n",
      "\u001b[32m[ \u001b[0m  90%\u001b[32m      ]\u001b[0m     9            0.101387                4.50\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m    10            0.101045                4.72\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: ./model.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 1.70 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 72.19 (sec)\u001b[0m\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 4 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from ./model.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1307939\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 2\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 6\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 0.14 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 7.19 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.101903\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 9.79 (sec)\u001b[0m\n",
      "roc_auc :  0.7871318647921568  log_loss :  0.10190580170485125\n",
      "k :  4  lambda :  0.001\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[35m\u001b[1m[ WARNING    ] Validation file not found, xLearn has already disable early-stopping.\u001b[0m\n",
      "\u001b[35m\u001b[1m[ WARNING    ] Validation file not found, xLearn has already disable (-x auc) option.\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mxLearn uses 4 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[------------] \u001b[0mBinary file (train.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1307939\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 6\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 33.30 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 249.47 MB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.38 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     1            0.106319                4.64\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     2            0.104869                4.91\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     3            0.104111                4.67\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m     4            0.103469                4.71\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m     5            0.102923                4.95\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m     6            0.102406                4.58\n",
      "\u001b[32m[ \u001b[0m  70%\u001b[32m      ]\u001b[0m     7            0.101981                4.99\n",
      "\u001b[32m[ \u001b[0m  80%\u001b[32m      ]\u001b[0m     8            0.101571                5.03\n",
      "\u001b[32m[ \u001b[0m  90%\u001b[32m      ]\u001b[0m     9            0.101178                4.42\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m    10            0.100830                4.47\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: ./model.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 1.79 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 82.96 (sec)\u001b[0m\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 4 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from ./model.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1307939\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 4\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 6\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 0.12 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 3.48 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.101708\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 8.28 (sec)\u001b[0m\n",
      "roc_auc :  0.7878120949625418  log_loss :  0.10171503791463421\n",
      "k :  8  lambda :  0.001\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[35m\u001b[1m[ WARNING    ] Validation file not found, xLearn has already disable early-stopping.\u001b[0m\n",
      "\u001b[35m\u001b[1m[ WARNING    ] Validation file not found, xLearn has already disable (-x auc) option.\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mxLearn uses 4 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1307939\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 6\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 11.63 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_test = pd.read_csv('y_test.csv')\n",
    "\n",
    "for k in k_value:\n",
    "    for l in l_value:\n",
    "        print('k : ', k, ' lambda : ', l)\n",
    "        ffm_model = xl.create_ffm()\n",
    "        ffm_model.setTrain(\"train.txt\")\n",
    "        ffm_model.setTest(\"test.txt\")\n",
    "        param = {'task':'binary', 'lr': 0.1, 'lambda': l, 'k': k, 'metric': 'auc'}\n",
    "\n",
    "        ffm_model.fit(param, './model.out')\n",
    "        ffm_model.setSigmoid()\n",
    "        ffm_model.predict('./model.out', './output.txt')\n",
    "\n",
    "        with open('output.txt', 'r') as f:\n",
    "            y_pred_proba = np.array(list(map(float, filter(lambda s: len(s) > 0, f.read().split('\\n')))))\n",
    "        roc_auc_metric = roc_auc_score(y_test, y_pred_proba)\n",
    "        log_loss_metric = log_loss(y_test, y_pred_proba)\n",
    "        print('roc_auc : ', roc_auc_metric, ' log_loss : ',log_loss_metric)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перебор параметров в одной сессии осуществляется плохо, но я выбрал параметры при которых работает хорошо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k :  4  lambda :  0.0001\n",
    "k = 4\n",
    "l = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k :  4  lambda :  0.0001\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[35m\u001b[1m[ WARNING    ] Validation file not found, xLearn has already disable early-stopping.\u001b[0m\n",
      "\u001b[35m\u001b[1m[ WARNING    ] Validation file not found, xLearn has already disable (-x auc) option.\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mxLearn uses 4 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1307939\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 6\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 7.78 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 249.47 MB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.32 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     1            0.104058                4.47\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     2            0.101375                4.39\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     3            0.099444                4.99\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m     4            0.097905                4.90\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m     5            0.096753                4.35\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m     6            0.095814                4.32\n",
      "\u001b[32m[ \u001b[0m  70%\u001b[32m      ]\u001b[0m     7            0.095022                4.39\n",
      "\u001b[32m[ \u001b[0m  80%\u001b[32m      ]\u001b[0m     8            0.094325                4.37\n",
      "\u001b[32m[ \u001b[0m  90%\u001b[32m      ]\u001b[0m     9            0.093744                4.39\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m    10            0.093247                4.36\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: ./model.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 1.40 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 54.49 (sec)\u001b[0m\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 4 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from ./model.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1307939\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 4\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 6\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 0.12 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (control_data.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.65 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.125367\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 2.62 (sec)\u001b[0m\n",
      "roc_auc :  0.8161625107335491  log_loss :  0.12536591553249926\n"
     ]
    }
   ],
   "source": [
    "y_control = pd.read_csv('y_control.csv')\n",
    "\n",
    "print('k : ', k, ' lambda : ', l)\n",
    "ffm_model = xl.create_ffm()\n",
    "ffm_model.setTrain(\"train.txt\")\n",
    "ffm_model.setTest(\"control_data.txt\")\n",
    "param = {'task':'binary', 'lr': 0.1, 'lambda': l, 'k': k, 'metric': 'auc'}\n",
    "\n",
    "ffm_model.fit(param, './model.out')\n",
    "ffm_model.setSigmoid()\n",
    "ffm_model.predict('./model.out', './output.txt')\n",
    "\n",
    "with open('output.txt', 'r') as f:\n",
    "    y_pred_proba = np.array(list(map(float, filter(lambda s: len(s) > 0, f.read().split('\\n')))))\n",
    "roc_auc_metric = roc_auc_score(y_control, y_pred_proba)\n",
    "log_loss_metric = log_loss(y_control, y_pred_proba)\n",
    "print('roc_auc : ', roc_auc_metric, ' log_loss : ',log_loss_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В прошлой домашней работе AUC:0.76, а в этой 0.81.\n",
    "\n",
    "В прошлой домашней работе logloss:0.14, а в этой 0.125\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
